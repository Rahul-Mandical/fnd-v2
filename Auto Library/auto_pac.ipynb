{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription : Complete model creation process as a single entity for passive aggresive classifier\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description : Complete model creation process as a single entity for passive aggresive classifier\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pac_tfidf_model(x,y,stop=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input  : x=Attributes of the dataset, y=Target Attribute\n",
    "    Output : Print model details\n",
    "    \n",
    "    \"\"\"\n",
    "    train_x,train_y,test_x,test_y=split_data(x,y)\n",
    "    \n",
    "    tfidf_train_x,tfidf_test_x=tfidf_vect(train_x,test_x)\n",
    "    \n",
    "    passive_aggressive(tfidf_train_x,train_y,tfidf_test_x,test_y,stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pac_hash_model(x,y,stop=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input  : x=Attributes of the dataset, y=Target Attribute\n",
    "    Output : Print model details\n",
    "    \n",
    "    \"\"\"\n",
    "    train_x,train_y,test_x,test_y=split_data(x,y)\n",
    "    \n",
    "    tfidf_train_x,tfidf_test_x=hash_vect(train_x,test_x)\n",
    "    \n",
    "    passive_aggressive(tfidf_train_x,train_y,tfidf_test_x,test_y,stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x,y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reminder : Clean the set before sending here.\n",
    "    Input  : x=Attributes of the dataset, y=Target Attribute\n",
    "    Output : Split data of train test\n",
    "    \n",
    "    We are removing dev , as dev can be better used for the models that includes DNN, CNN and RNN\n",
    "    \n",
    "    \"\"\"\n",
    "    X=x\n",
    "    Y=y\n",
    "    \n",
    "    train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.2,random_state=12)\n",
    "    \n",
    "    #train_x : Training data with attributes\n",
    "    #train_y : Training data with ratings\n",
    "    #test_x  : testing data with attributes\n",
    "    #test_y  : testing data with rating \n",
    "    \n",
    "    print(\"Final size of train/test :\",train_x.size,\"/\",test_x.size)\n",
    "    return train_x,train_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vect(train_x,test_x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input : train and text attributes needed to be vectorized\n",
    "    Output : Vectorized versions of the input\n",
    "    \n",
    "    \"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7)   # a TFIDF vectorizer\n",
    "    tfidf_train_x = tfidf_vectorizer.fit_transform(train_x)  #fitting the training data\n",
    "    tfidf_test_x = tfidf_vectorizer.transform(test_x)  #fitting the testing data\n",
    "    return tfidf_train_x,tfidf_test_x    #returning a vectorized train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_vect(train_x,test_x):  \n",
    "    \"\"\"\n",
    "    Input : train and text attributes needed to be vectorized\n",
    "    Output : Vectorized versions of the input\n",
    "    \n",
    "    \"\"\"\n",
    "    hash_vectorizer = HashingVectorizer(stop_words='english')  #creating a hashing vectorizer\n",
    "    hash_train_x = np.absolute(hash_vectorizer.fit_transform(train_x)) #fitting the training data\n",
    "    hash_test_x = np.absolute(hash_vectorizer.transform(test_x)) #fitting the testing data\n",
    "    return hash_train_x,hash_test_x  #returning a vectorized train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passive_aggressive(train_x,train_y,test_x,test_y,stop=False):\n",
    "    \n",
    "    if stop==True:\n",
    "        print(\"Early Stopping is being used\")\n",
    "    \n",
    "    pac= PassiveAggressiveClassifier(early_stopping=stop)\n",
    "    pac.fit(train_x, train_y)\n",
    "    predicted_pac_train=pac.predict(train_x)\n",
    "    predicted_pac_test= pac.predict(test_x)\n",
    "    \n",
    "    score_train= metrics.accuracy_score(train_y, predicted_pac_train)\n",
    "    score_test=metrics.accuracy_score(test_y,predicted_pac_test)\n",
    "    \n",
    "    print(\"train accuracy:\",score_train)\n",
    "    cm_pac_train= metrics.confusion_matrix(train_y, predicted_pac_train)\n",
    "    print(\"train confusion matrix\")\n",
    "    print(cm_pac_train)\n",
    "    print(\"test accuracy:\",score_test)\n",
    "    cm_pac_test= metrics.confusion_matrix(test_y, predicted_pac_test)\n",
    "    print(\"test confusion matrix\")\n",
    "    print(cm_pac_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
