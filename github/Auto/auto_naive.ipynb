{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription : Complete model creation process as a single entity for naive bayes \\nGrid search has been used\\nTODO - Test Grid Search better , Choose a better metric?\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description : Complete model creation process as a single entity for naive bayes \n",
    "Grid search has been used\n",
    "TODO - Test Grid Search better , Choose a better metric?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navie_bayes_tfidf_model(x,y,itera=1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input  : x=Attributes of the dataset, y=Target Attribute\n",
    "    Output : Print model details\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_x,train_y,test_x,test_y=split_data(x,y)\n",
    "    \n",
    "    print(\"train_x :\",train_x.shape )\n",
    "    print(\"train_y :\",train_y.shape )\n",
    "    print(\"test_x :\",test_x.shape )\n",
    "    print(\"test_y :\",test_y.shape )\n",
    "    \n",
    "    tfidf_train_x,tfidf_test_x=tfidf_vect(train_x,test_x)\n",
    "\n",
    "    \n",
    "    navie_bayes(tfidf_train_x,train_y,tfidf_test_x,test_y,itera=1000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navie_bayes_hash_model(x,y,itera=1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input  : x=Attributes of the dataset, y=Target Attribute\n",
    "    Output : Print model details\n",
    "    \n",
    "    \"\"\"\n",
    "    train_x,train_y,test_x,test_y=split_data(x,y)\n",
    "    \n",
    "    tfidf_train_x,tfidf_test_x=hash_vect(train_x,test_x)\n",
    "    \n",
    "    navie_bayes(tfidf_train_x,train_y,tfidf_test_x,test_y,itera=1000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x,y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reminder : Clean the set before sending here.\n",
    "    Input  : x=Attributes of the dataset, y=Target Attribute\n",
    "    Output : Split data of train test\n",
    "    \n",
    "    We are removing dev , as dev can be better used for the models that includes DNN, CNN and RNN\n",
    "    \n",
    "    \"\"\"\n",
    "    X=x\n",
    "    Y=y\n",
    "    print('Splitting')\n",
    "    train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.2,random_state=12)\n",
    "    \n",
    "    #train_x : Training data with attributes\n",
    "    #train_y : Training data with ratings\n",
    "    #test_x  : testing data with attributes\n",
    "    #test_y  : testing data with rating \n",
    "    \n",
    "    print(\"Final size of train/test :\",train_x.size,\"/\",test_x.size)\n",
    "    return train_x,train_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vect(train_x,test_x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input : train and text attributes needed to be vectorized\n",
    "    Output : Vectorized versions of the input\n",
    "    \n",
    "    \"\"\"\n",
    "    print('Vectorizing')\n",
    "    print(\"test_x :\",test_x.shape )\n",
    "    print(\"train_x :\",train_x.shape )\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7)   # a TFIDF vectorizer $min_df=0.03\n",
    "    tfidf_train_x = tfidf_vectorizer.fit_transform(train_x)  #fitting the training data\n",
    "    tfidf_test_x = tfidf_vectorizer.transform(test_x)  #fitting the testing data\n",
    "    print(\"tfidf_train_x : \",tfidf_train_x.shape)\n",
    "    print(\"tfidf_test_x : \",tfidf_test_x.shape)\n",
    "    return tfidf_train_x,tfidf_test_x    #returning a vectorized train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_vect(train_x,test_x):  \n",
    "    \"\"\"\n",
    "    Input : train and text attributes needed to be vectorized\n",
    "    Output : Vectorized versions of the input\n",
    "    \n",
    "    \"\"\"\n",
    "    print('Vectorizing')\n",
    "\n",
    "    hash_vectorizer = HashingVectorizer(stop_words='english')  #creating a hashing vectorizer\n",
    "    hash_train_x = np.absolute(hash_vectorizer.fit_transform(train_x)) #fitting the training data\n",
    "    hash_test_x = np.absolute(hash_vectorizer.transform(test_x)) #fitting the testing data\n",
    "    return hash_train_x,hash_test_x  #returning a vectorized train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def navie_bayes(train_x,train_y,test_x,test_y,itera=1000):\n",
    "   \n",
    "    print('model building')\n",
    "    NBG = MultinomialNB()\n",
    "    if itera == 1000:\n",
    "        alphas=np.arange(0.001,1,0.001)\n",
    "    else:\n",
    "        alphas=np.arange(0.01,1,0.01)\n",
    "    print('begin grid')\n",
    "    grid = GridSearchCV(estimator=NBG, param_grid=dict(alpha=alphas))\n",
    "\n",
    "    grid.fit(train_x, train_y)\n",
    "    \n",
    "    #print(grid)\n",
    "    # summarize the results of the grid search\n",
    "    print(\"grid score\",grid.best_score_)\n",
    "    print(\"grid alpha\",grid.best_estimator_.alpha)\n",
    "    alpha=grid.best_estimator_.alpha\n",
    "    \n",
    "    NB = MultinomialNB(alpha = alpha )\n",
    "    NB.fit(train_x,train_y)  \n",
    "    predict_NB_train = NB.predict(train_x) \n",
    "    predict_NB_test = NB.predict(test_x) \n",
    "    score_train = metrics.accuracy_score(train_y, predict_NB_train) \n",
    "    score_test = metrics.accuracy_score(test_y, predict_NB_test)\n",
    "      \n",
    "    print(\"Alpha: {:.3f} test_Score: {:.5f} train_score: {:.5f}\".format(alpha,score_test,score_train))# checking tha accuracy \n",
    "       \n",
    "    #print(\"best accuracy with Alpha: {:.2f} Score: {:.5f}\".format(alpha_value, best_score))\n",
    "    cm_train= metrics.confusion_matrix(train_y, predict_NB_train)\n",
    "    print(\"training confusion matrix\")\n",
    "    print(cm_train)\n",
    "    cm_test = metrics.confusion_matrix(test_y, predict_NB_test)\n",
    "    print(\"testing confusion matrix\")\n",
    "    print(cm_test)\n",
    "    \n",
    "    print(\"------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
