{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from auto_naive.ipynb\n",
      "importing Jupyter notebook from auto_pac.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import auto_naive as an\n",
    "import auto_pac as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (1,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv('datasets/pontes set/resized_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'domain', 'type', 'url', 'content', 'scraped_at',\n",
       "       'inserted_at', 'updated_at', 'title', 'authors', 'keywords',\n",
       "       'meta_keywords', 'meta_description', 'tags', 'summary', 'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['clickbait', 'satire', 'unreliable', 'hate', 'reliable',\n",
       "       'conspiracy', 'fake', 'political', 'bias', 'rumor', 'junksci', nan,\n",
       "       'unknown', '2018-02-10 13:43:39.521661'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426550, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSo much columns \\nSo many rows\\nSo many types \\n;-;\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "So much columns \n",
    "So many rows\n",
    "So many types \n",
    ";-;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426545</td>\n",
       "      <td>426545</td>\n",
       "      <td>9878188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426546</td>\n",
       "      <td>426546</td>\n",
       "      <td>9878196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426547</td>\n",
       "      <td>426547</td>\n",
       "      <td>9878220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426548</td>\n",
       "      <td>426548</td>\n",
       "      <td>9878237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426549</td>\n",
       "      <td>426549</td>\n",
       "      <td>9878253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426550 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       id\n",
       "0                0       21\n",
       "1                1       22\n",
       "2                2       54\n",
       "3                3       61\n",
       "4                4       64\n",
       "...            ...      ...\n",
       "426545      426545  9878188\n",
       "426546      426546  9878196\n",
       "426547      426547  9878220\n",
       "426548      426548  9878237\n",
       "426549      426549  9878253\n",
       "\n",
       "[426550 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:,0:2]\n",
    "\n",
    "#here the first column i,e unnamed and id will be dropped as they are not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['id', 'Unnamed: 0'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['domain', 'type', 'url', 'content', 'scraped_at', 'inserted_at',\n",
      "       'updated_at', 'title', 'authors', 'keywords', 'meta_keywords',\n",
      "       'meta_description', 'tags', 'summary', 'source'],\n",
      "      dtype='object')\n",
      "(426550, 15)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             NaN\n",
       "1             NaN\n",
       "2             NaN\n",
       "3             NaN\n",
       "4             NaN\n",
       "           ...   \n",
       "426545    nytimes\n",
       "426546    nytimes\n",
       "426547    nytimes\n",
       "426548    nytimes\n",
       "426549    nytimes\n",
       "Name: source, Length: 426550, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.source\n",
    "\n",
    "#domain is the website with which it was accessed\n",
    "#type is the label\n",
    "#url is not required as the domain covers the website which we got in \n",
    "#content is very important\n",
    "#all 3 at dates are not important\n",
    "#title is required\n",
    "#authors too\n",
    "#all keywords are NaN, an guessing this gets updated after applying nlp\n",
    "#meta keywords are just weird, missing and weird\n",
    "#meta description has NAn but unsure how useful this is\n",
    "#Removing tags due to too many missing values\n",
    "#summary all NAN\n",
    "#how is source different from domain\n",
    "#remove extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain                0.001172\n",
       "type                  4.723948\n",
       "url                   0.001172\n",
       "content               0.001172\n",
       "scraped_at            0.001407\n",
       "inserted_at           0.001407\n",
       "updated_at            0.001407\n",
       "title                 0.853827\n",
       "authors              44.418708\n",
       "keywords            100.000000\n",
       "meta_keywords         4.017583\n",
       "meta_description     52.563357\n",
       "tags                 76.969640\n",
       "summary             100.000000\n",
       "source               77.875982\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()/(len(dataset))*100\n",
    "#shows percentage of nulls\n",
    "#source gets dropped due to too much null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['url', 'scraped_at', 'inserted_at', 'updated_at','keywords', 'meta_keywords',\n",
    "       'meta_description', 'tags', 'summary'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['source'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain      0.001172\n",
       "type        4.723948\n",
       "content     0.001172\n",
       "title       0.853827\n",
       "authors    44.418708\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()/(len(dataset))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rename(columns={\"type\": \"label\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2 new routes will be established now\\n\\nRoute 1: Remove authors and continue\\nRoute 2: Since authors are important, we can remove all rows whose authors value is nan\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2 new routes will be established now\n",
    "\n",
    "Route 1: Remove authors and continue\n",
    "Route 2: Since authors are important, we can remove all rows whose authors value is nan\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nTaking route 1 now :)\\ndrop authors\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Taking route 1 now :)\n",
    "drop authors\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=dataset.drop(['authors'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['domain', 'label', 'content', 'title'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426550, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['clickbait', 'satire', 'unreliable', 'hate', 'reliable',\n",
       "       'conspiracy', 'fake', 'political', 'bias', 'rumor', 'junksci', nan,\n",
       "       'unknown', '2018-02-10 13:43:39.521661'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.label.unique()\n",
    "#click baits are false\n",
    "#satire can be true or false\n",
    "#hate unknown\n",
    "#reliable is true\n",
    "#conspiracy can be true, or wait is it a conspiracy that all conspiracies are false?\n",
    "#fake is fake \n",
    "#political and everything else are ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_r1=r1[r1.label == 'clickbait']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_r1=r1[r1.label == 'reliable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_r1=r1[r1.label == 'fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46288 384096 177840\n"
     ]
    }
   ],
   "source": [
    "print(c_r1.size,d_r1.size,e_r1.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_clean=pd.concat([c_r1,d_r1,e_r1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_clean.replace({'clickbait':'fake'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fake', 'reliable'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_clean.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_clean.shape\n",
    "r1_clean.to_csv('datasets/pontes set/route1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrerun from here\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "rerun from here\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "route1=pd.read_csv('datasets/pontes set/route1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152056, 4)\n",
      "Index(['domain', 'label', 'content', 'title'], dtype='object')\n",
      "                 domain label  \\\n",
      "0  bipartisanreport.com  fake   \n",
      "1  bipartisanreport.com  fake   \n",
      "2  bipartisanreport.com  fake   \n",
      "3       breaking911.com  fake   \n",
      "4  bipartisanreport.com  fake   \n",
      "5  bipartisanreport.com  fake   \n",
      "\n",
      "                                             content  \\\n",
      "0  The website from which you got to this page is...   \n",
      "1  When the news broke that Stephanie Clifford, a...   \n",
      "2  President Trump’s year or so in office has bee...   \n",
      "3  Baltimore — David Thornton was found guilty by...   \n",
      "4  The federal government remained shut down goin...   \n",
      "5  Special Counsel Robert S. Mueller is doing any...   \n",
      "\n",
      "                                               title  \n",
      "0                                   Email Protection  \n",
      "1  ‘Wall St Journal’ Rocks Trump With Friday Shad...  \n",
      "2  John Kelly Is On His Way Out And Ivanka Trump ...  \n",
      "3  Murderer on Parole Receives Maximum Sentence A...  \n",
      "4  NY Times Reveals Why Trump Is Refusing A DACA ...  \n",
      "5  N.Y. Post Drops Lewandowski Testimony Bombshel...  \n",
      "['fake' 'reliable']\n"
     ]
    }
   ],
   "source": [
    "print(route1.shape)\n",
    "print(route1.columns)\n",
    "print(route1.head(6))\n",
    "print(route1.label.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "route1.dropna(subset=[\"title\"], inplace=True)\n",
    "route1.shape\n",
    "route1_y=route1.label\n",
    "route1_x=route1.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152055,)\n",
      "(152055, 3)\n",
      "Index(['domain', 'content', 'title'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(route1_y.shape)\n",
    "print(route1_x.shape)\n",
    "print(route1_x.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbuild models for route 1 naive bayes\\nFake :224128\\nTruth:384096 \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "build models for route 1 naive bayes\n",
    "Fake :224128\n",
    "Truth:384096 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain     0.0\n",
       "label      0.0\n",
       "content    0.0\n",
       "title      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route1.isna().sum()/(len(route1))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain     0\n",
       "label      0\n",
       "content    0\n",
       "title      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route1.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "train_x : (121644,)\n",
      "train_y : (121644,)\n",
      "test_x : (30411,)\n",
      "test_y : (30411,)\n",
      "Vectorizing\n",
      "test_x : (30411,)\n",
      "train_x : (121644,)\n",
      "tfidf_train_x :  (121644, 176)\n",
      "tfidf_test_x :  (30411, 176)\n",
      "model building\n",
      "begin grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid score 1.0\n",
      "grid alpha 0.001\n",
      "Alpha: 0.001 test_Score: 0.99997 train_score: 1.00000\n",
      "training confusion matrix\n",
      "[[44965     0]\n",
      " [    0 76679]]\n",
      "testing confusion matrix\n",
      "[[11065     1]\n",
      " [    0 19345]]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "an.navie_bayes_tfidf_model(route1_x.domain,route1_y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "train_x : (121644,)\n",
      "train_y : (121644,)\n",
      "test_x : (30411,)\n",
      "test_y : (30411,)\n",
      "Vectorizing\n",
      "test_x : (30411,)\n",
      "train_x : (121644,)\n",
      "tfidf_train_x :  (121644, 378240)\n",
      "tfidf_test_x :  (30411, 378240)\n",
      "model building\n",
      "begin grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid score 0.9030120680017099\n",
      "grid alpha 0.006\n",
      "Alpha: 0.006 test_Score: 0.90773 train_score: 0.95508\n",
      "training confusion matrix\n",
      "[[32090  3528]\n",
      " [ 1936 84090]]\n",
      "testing confusion matrix\n",
      "[[ 6868  1973]\n",
      " [  833 20737]]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "an.navie_bayes_tfidf_model(route1_x.content,route1_y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "train_x : (121644,)\n",
      "train_y : (121644,)\n",
      "test_x : (30411,)\n",
      "test_y : (30411,)\n",
      "Vectorizing\n",
      "test_x : (30411,)\n",
      "train_x : (121644,)\n",
      "tfidf_train_x :  (121644, 61767)\n",
      "tfidf_test_x :  (30411, 61767)\n",
      "model building\n",
      "begin grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid score 0.7973677287823485\n",
      "grid alpha 0.17200000000000001\n",
      "Alpha: 0.172 test_Score: 0.80057 train_score: 0.87703\n",
      "training confusion matrix\n",
      "[[22769 12849]\n",
      " [ 2109 83917]]\n",
      "testing confusion matrix\n",
      "[[ 3997  4844]\n",
      " [ 1221 20349]]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "an.navie_bayes_tfidf_model(route1_x.title,route1_y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Vectorizing\n",
      "model building\n",
      "begin grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid score 0.9998602479366019\n",
      "grid alpha 0.001\n",
      "Alpha: 0.001 test_Score: 1.00000 train_score: 1.00000\n",
      "training confusion matrix\n",
      "[[35618     0]\n",
      " [    0 86026]]\n",
      "testing confusion matrix\n",
      "[[ 8841     0]\n",
      " [    0 21570]]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "an.navie_bayes_hash_model(route1_x.domain,route1_y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Vectorizing\n",
      "model building\n",
      "begin grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid score 0.9092598073065667\n",
      "grid alpha 0.001\n",
      "Alpha: 0.001 test_Score: 0.91230 train_score: 0.94406\n",
      "training confusion matrix\n",
      "[[31231  4387]\n",
      " [ 2418 83608]]\n",
      "testing confusion matrix\n",
      "[[ 7063  1778]\n",
      " [  889 20681]]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "an.navie_bayes_hash_model(route1_x.content,route1_y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Vectorizing\n",
      "model building\n",
      "begin grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid score 0.7927065864325409\n",
      "grid alpha 0.006\n",
      "Alpha: 0.006 test_Score: 0.79882 train_score: 0.88309\n",
      "training confusion matrix\n",
      "[[23627 11991]\n",
      " [ 2231 83795]]\n",
      "testing confusion matrix\n",
      "[[ 4284  4557]\n",
      " [ 1561 20009]]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "an.navie_bayes_hash_model(route1_x.title,route1_y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([])\n",
    "a.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_tfidf(x1,x2,y,x3=a,itera=100):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    if x3.size==0:\n",
    "        train_x1,train_y1,test_x1,test_y1=an.split_data(x1,y)\n",
    "        train_x2,train_y2,test_x2,test_y2=an.split_data(x2,y)\n",
    "\n",
    "\n",
    "\n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7,min_df=0.02)   # a TFIDF vectorizer\n",
    "        tfidf_train_x1 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x1).todense())  #fitting the training data\n",
    "        tfidf_test_x1 = pd.DataFrame(tfidf_vectorizer.transform(test_x1).todense())\n",
    "\n",
    "        tfidf_train_x2 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x2).todense())  #fitting the training data\n",
    "        tfidf_test_x2 = pd.DataFrame(tfidf_vectorizer.transform(test_x2).todense()) \n",
    "\n",
    "        train=pd.concat([tfidf_train_x1,tfidf_train_x2],axis=1)\n",
    "        test=pd.concat([tfidf_test_x1,tfidf_test_x2],axis=1)\n",
    "        print(train.shape)\n",
    "        print(test.shape)\n",
    "        print(train_y2.shape)\n",
    "        print(test_y2.shape)\n",
    "\n",
    "        an.navie_bayes(train,train_y2,test,test_y2,itera)\n",
    "    \n",
    "    else:\n",
    "        train_x1,train_y1,test_x1,test_y1=an.split_data(x1,y)\n",
    "        train_x2,train_y2,test_x2,test_y2=an.split_data(x2,y)\n",
    "        train_x3,train_y3,test_x3,test_y3=an.split_data(x3,y)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7,min_df=0.02)   # a TFIDF vectorizer\n",
    "        tfidf_train_x1 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x1).todense())  #fitting the training data\n",
    "        tfidf_test_x1 = pd.DataFrame(tfidf_vectorizer.transform(test_x1).todense())\n",
    "\n",
    "        tfidf_train_x2 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x2).todense())  #fitting the training data\n",
    "        tfidf_test_x2 = pd.DataFrame(tfidf_vectorizer.transform(test_x2).todense()) \n",
    "        \n",
    "        tfidf_train_x3 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x3).todense())  #fitting the training data\n",
    "        tfidf_test_x3 = pd.DataFrame(tfidf_vectorizer.transform(test_x3).todense())\n",
    "        \n",
    "        train=pd.concat([tfidf_train_x1,tfidf_train_x2,tfidf_train_x3],axis=1)\n",
    "        test=pd.concat([tfidf_test_x1,tfidf_test_x2,tfidf_test_x3],axis=1)\n",
    "        \n",
    "        an.navie_bayes(train,train_y2,test,test_y2,itera)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "model building\n",
      "begin grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid score 0.9653743711157147\n",
      "grid alpha 0.79\n",
      "Alpha: 0.790 test_Score: 0.96613 train_score: 0.96566\n",
      "training confusion matrix\n",
      "[[42409  2556]\n",
      " [ 1621 75058]]\n",
      "testing confusion matrix\n",
      "[[10423   643]\n",
      " [  387 18958]]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mult_tfidf(x1=route1_x.domain,x2=route1_x.content,x3=route1_x.title,y=route1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "(121644, 1730)\n",
      "(30411, 1730)\n",
      "(121644,)\n",
      "(30411,)\n",
      "model building\n",
      "begin grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid score 0.9649551149255203\n",
      "grid alpha 0.44\n",
      "Alpha: 0.440 test_Score: 0.96557 train_score: 0.96521\n",
      "training confusion matrix\n",
      "[[42149  2816]\n",
      " [ 1416 75263]]\n",
      "testing confusion matrix\n",
      "[[10358   708]\n",
      " [  339 19006]]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mult_tfidf(x1=route1_x.domain,x2=route1_x.content,y=route1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hash has been ignored because of memory errors\n",
    "unto to pac\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final size of train/test : 121644 / 30411\n",
      "train accuracy: 1.0\n",
      "train confusion matrix\n",
      "[[44965     0]\n",
      " [    0 76679]]\n",
      "test accuracy: 1.0\n",
      "test confusion matrix\n",
      "[[11066     0]\n",
      " [    0 19345]]\n"
     ]
    }
   ],
   "source": [
    "ap.pac_tfidf_model(route1_x.domain,route1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final size of train/test : 121644 / 30411\n",
      "train accuracy: 0.9999588964519417\n",
      "train confusion matrix\n",
      "[[44962     3]\n",
      " [    2 76677]]\n",
      "test accuracy: 0.9441320574792016\n",
      "test confusion matrix\n",
      "[[10229   837]\n",
      " [  862 18483]]\n"
     ]
    }
   ],
   "source": [
    "ap.pac_tfidf_model(route1_x.content,route1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final size of train/test : 121644 / 30411\n",
      "Early Stopping is being used\n",
      "train accuracy: 0.904837065535497\n",
      "train confusion matrix\n",
      "[[38107  6858]\n",
      " [ 4718 71961]]\n",
      "test accuracy: 0.7895827167801125\n",
      "test confusion matrix\n",
      "[[ 7433  3633]\n",
      " [ 2766 16579]]\n"
     ]
    }
   ],
   "source": [
    "ap.pac_tfidf_model(route1_x.title,route1_y,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final size of train/test : 121644 / 30411\n",
      "Early Stopping is being used\n",
      "train accuracy: 0.9043356022491862\n",
      "train confusion matrix\n",
      "[[38393  6572]\n",
      " [ 5065 71614]]\n",
      "test accuracy: 0.7884975831113742\n",
      "test confusion matrix\n",
      "[[ 7539  3527]\n",
      " [ 2905 16440]]\n"
     ]
    }
   ],
   "source": [
    "ap.pac_tfidf_model(route1_x.title,route1_y,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final size of train/test : 121644 / 30411\n",
      "Early Stopping is being used\n",
      "train accuracy: 1.0\n",
      "train confusion matrix\n",
      "[[44965     0]\n",
      " [    0 76679]]\n",
      "test accuracy: 1.0\n",
      "test confusion matrix\n",
      "[[11066     0]\n",
      " [    0 19345]]\n"
     ]
    }
   ],
   "source": [
    "ap.pac_tfidf_model(route1_x.domain,route1_y,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final size of train/test : 121644 / 30411\n",
      "Early Stopping is being used\n",
      "train accuracy: 0.9935303015356286\n",
      "train confusion matrix\n",
      "[[44588   377]\n",
      " [  410 76269]]\n",
      "test accuracy: 0.9464338561704646\n",
      "test confusion matrix\n",
      "[[10242   824]\n",
      " [  805 18540]]\n"
     ]
    }
   ],
   "source": [
    "ap.pac_tfidf_model(route1_x.content,route1_y,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_tfidf_pac(x1,x2,y,x3=a,stop=False):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    if x3.size==0:\n",
    "        train_x1,train_y1,test_x1,test_y1=an.split_data(x1,y)\n",
    "        train_x2,train_y2,test_x2,test_y2=an.split_data(x2,y)\n",
    "\n",
    "\n",
    "\n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7,min_df=0.02)   # a TFIDF vectorizer\n",
    "        tfidf_train_x1 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x1).todense())  #fitting the training data\n",
    "        tfidf_test_x1 = pd.DataFrame(tfidf_vectorizer.transform(test_x1).todense())\n",
    "\n",
    "        tfidf_train_x2 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x2).todense())  #fitting the training data\n",
    "        tfidf_test_x2 = pd.DataFrame(tfidf_vectorizer.transform(test_x2).todense()) \n",
    "\n",
    "        train=pd.concat([tfidf_train_x1,tfidf_train_x2],axis=1)\n",
    "        test=pd.concat([tfidf_test_x1,tfidf_test_x2],axis=1)\n",
    "        print(train.shape)\n",
    "        print(test.shape)\n",
    "        print(train_y2.shape)\n",
    "        print(test_y2.shape)\n",
    "\n",
    "        ap.passive_aggressive(train,train_y2,test,test_y2,stop)\n",
    "    \n",
    "    else:\n",
    "        train_x1,train_y1,test_x1,test_y1=an.split_data(x1,y)\n",
    "        train_x2,train_y2,test_x2,test_y2=an.split_data(x2,y)\n",
    "        train_x3,train_y3,test_x3,test_y3=an.split_data(x3,y)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7,min_df=0.02)   # a TFIDF vectorizer\n",
    "        tfidf_train_x1 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x1).todense())  #fitting the training data\n",
    "        tfidf_test_x1 = pd.DataFrame(tfidf_vectorizer.transform(test_x1).todense())\n",
    "\n",
    "        tfidf_train_x2 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x2).todense())  #fitting the training data\n",
    "        tfidf_test_x2 = pd.DataFrame(tfidf_vectorizer.transform(test_x2).todense()) \n",
    "        \n",
    "        tfidf_train_x3 = pd.DataFrame(tfidf_vectorizer.fit_transform(train_x3).todense())  #fitting the training data\n",
    "        tfidf_test_x3 = pd.DataFrame(tfidf_vectorizer.transform(test_x3).todense())\n",
    "        \n",
    "        train=pd.concat([tfidf_train_x1,tfidf_train_x2,tfidf_train_x3],axis=1)\n",
    "        test=pd.concat([tfidf_test_x1,tfidf_test_x2,tfidf_test_x3],axis=1)\n",
    "        \n",
    "        ap.passive_aggressive(train,train_y2,test,test_y2,stop)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "train accuracy: 0.9892801946664036\n",
      "train confusion matrix\n",
      "[[44723   242]\n",
      " [ 1062 75617]]\n",
      "test accuracy: 0.9845121830916445\n",
      "test confusion matrix\n",
      "[[10947   119]\n",
      " [  352 18993]]\n"
     ]
    }
   ],
   "source": [
    "mult_tfidf_pac(x1=route1_x.domain,x2=route1_x.content,x3=route1_x.title,y=route1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Early Stopping is being used\n",
      "train accuracy: 0.9900447206602874\n",
      "train confusion matrix\n",
      "[[44368   597]\n",
      " [  614 76065]]\n",
      "test accuracy: 0.9850054256683437\n",
      "test confusion matrix\n",
      "[[10842   224]\n",
      " [  232 19113]]\n"
     ]
    }
   ],
   "source": [
    "mult_tfidf_pac(x1=route1_x.domain,x2=route1_x.content,x3=route1_x.title,y=route1_y,stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "(121644, 1730)\n",
      "(30411, 1730)\n",
      "(121644,)\n",
      "(30411,)\n",
      "train accuracy: 0.977401269277564\n",
      "train confusion matrix\n",
      "[[42372  2593]\n",
      " [  156 76523]]\n",
      "test accuracy: 0.973627963565815\n",
      "test confusion matrix\n",
      "[[10348   718]\n",
      " [   84 19261]]\n"
     ]
    }
   ],
   "source": [
    "mult_tfidf_pac(x1=route1_x.domain,x2=route1_x.content,y=route1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "Splitting\n",
      "Final size of train/test : 121644 / 30411\n",
      "(121644, 1730)\n",
      "(30411, 1730)\n",
      "(121644,)\n",
      "(30411,)\n",
      "Early Stopping is being used\n",
      "train accuracy: 0.9892555325375686\n",
      "train confusion matrix\n",
      "[[44726   239]\n",
      " [ 1068 75611]]\n",
      "test accuracy: 0.9850054256683437\n",
      "test confusion matrix\n",
      "[[10959   107]\n",
      " [  349 18996]]\n"
     ]
    }
   ],
   "source": [
    "mult_tfidf_pac(x1=route1_x.domain,x2=route1_x.content,y=route1_y,stop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
