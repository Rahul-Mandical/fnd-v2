{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dtale as d\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('route2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['domain', 'type', 'content', 'title', 'authors'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93018, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93018, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>Meditation Comprehension\\r\\n\\r\\nHeadline: Bitc...</td>\n",
       "      <td>Meditation Comprehension</td>\n",
       "      <td>Ethan Indigo Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>Zurich Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>ES Morning Update January 25th 2018\\r\\n\\r\\nHea...</td>\n",
       "      <td>ES Morning Update January 25th 2018</td>\n",
       "      <td>Red Dragon Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>Bang! Secret FISA Memo Released…You Won’t Beli...</td>\n",
       "      <td>Bang! Secret FISA Memo Released…You Won’t Beli...</td>\n",
       "      <td>Lisa Haven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>Obama’s The Greatest Criminal In History Say T...</td>\n",
       "      <td>Obama DOJ Bombshell: Investigators Just Uncove...</td>\n",
       "      <td>Economic News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93013</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Watching is The New York Times’s TV and film r...</td>\n",
       "      <td>A Starter Guide to Streaming Great South Korea...</td>\n",
       "      <td>Dakota Kim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93014</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>WHERE TO GO NOW In Philadelphia, the Ultimate ...</td>\n",
       "      <td>In Philadelphia, the Ultimate Eagles Celebrati...</td>\n",
       "      <td>John L. Dorman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93015</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>“The Illinois Republican Party and our country...</td>\n",
       "      <td>He’s a Nazi, Republicans Warn, but He’s Their ...</td>\n",
       "      <td>Liam Stack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93016</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Most prominent is the lighthouse. The 90-foot-...</td>\n",
       "      <td>Lighthouse Hill, Staten Island: Small and Semi...</td>\n",
       "      <td>Julie Lasky, Living In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93017</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Photo\\r\\n\\r\\nHave you ridden on an airplane re...</td>\n",
       "      <td>Are Emotional-Support Animals a Scam?</td>\n",
       "      <td>Natalie Proulx, Student Opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93018 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  domain      type  \\\n",
       "0      beforeitsnews.com      fake   \n",
       "1      beforeitsnews.com      fake   \n",
       "2      beforeitsnews.com      fake   \n",
       "3      beforeitsnews.com      fake   \n",
       "4      beforeitsnews.com      fake   \n",
       "...                  ...       ...   \n",
       "93013        nytimes.com  reliable   \n",
       "93014        nytimes.com  reliable   \n",
       "93015        nytimes.com  reliable   \n",
       "93016        nytimes.com  reliable   \n",
       "93017        nytimes.com  reliable   \n",
       "\n",
       "                                                 content  \\\n",
       "0      Meditation Comprehension\\r\\n\\r\\nHeadline: Bitc...   \n",
       "1      AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2      ES Morning Update January 25th 2018\\r\\n\\r\\nHea...   \n",
       "3      Bang! Secret FISA Memo Released…You Won’t Beli...   \n",
       "4      Obama’s The Greatest Criminal In History Say T...   \n",
       "...                                                  ...   \n",
       "93013  Watching is The New York Times’s TV and film r...   \n",
       "93014  WHERE TO GO NOW In Philadelphia, the Ultimate ...   \n",
       "93015  “The Illinois Republican Party and our country...   \n",
       "93016  Most prominent is the lighthouse. The 90-foot-...   \n",
       "93017  Photo\\r\\n\\r\\nHave you ridden on an airplane re...   \n",
       "\n",
       "                                                   title  \\\n",
       "0                               Meditation Comprehension   \n",
       "1      AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2                    ES Morning Update January 25th 2018   \n",
       "3      Bang! Secret FISA Memo Released…You Won’t Beli...   \n",
       "4      Obama DOJ Bombshell: Investigators Just Uncove...   \n",
       "...                                                  ...   \n",
       "93013  A Starter Guide to Streaming Great South Korea...   \n",
       "93014  In Philadelphia, the Ultimate Eagles Celebrati...   \n",
       "93015  He’s a Nazi, Republicans Warn, but He’s Their ...   \n",
       "93016  Lighthouse Hill, Staten Island: Small and Semi...   \n",
       "93017              Are Emotional-Support Animals a Scam?   \n",
       "\n",
       "                               authors  \n",
       "0                   Ethan Indigo Smith  \n",
       "1                         Zurich Times  \n",
       "2                       Red Dragon Leo  \n",
       "3                           Lisa Haven  \n",
       "4                        Economic News  \n",
       "...                                ...  \n",
       "93013                       Dakota Kim  \n",
       "93014                   John L. Dorman  \n",
       "93015                       Liam Stack  \n",
       "93016           Julie Lasky, Living In  \n",
       "93017  Natalie Proulx, Student Opinion  \n",
       "\n",
       "[93018 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['domain', 'content', 'title', 'authors', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"350\"\n",
       "            src=\"http://DESKTOP-G082NI4:40000/dtale/iframe/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f946716908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=d.show(data)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Meditation Comprehension\\r\\n\\r\\nHeadline: Bitc...</td>\n",
       "      <td>Meditation Comprehension</td>\n",
       "      <td>Ethan Indigo Smith</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>Zurich Times</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>ES Morning Update January 25th 2018\\r\\n\\r\\nHea...</td>\n",
       "      <td>ES Morning Update January 25th 2018</td>\n",
       "      <td>Red Dragon Leo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Bang! Secret FISA Memo Released…You Won’t Beli...</td>\n",
       "      <td>Bang! Secret FISA Memo Released…You Won’t Beli...</td>\n",
       "      <td>Lisa Haven</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Obama’s The Greatest Criminal In History Say T...</td>\n",
       "      <td>Obama DOJ Bombshell: Investigators Just Uncove...</td>\n",
       "      <td>Economic News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93013</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Watching is The New York Times’s TV and film r...</td>\n",
       "      <td>A Starter Guide to Streaming Great South Korea...</td>\n",
       "      <td>Dakota Kim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93014</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>WHERE TO GO NOW In Philadelphia, the Ultimate ...</td>\n",
       "      <td>In Philadelphia, the Ultimate Eagles Celebrati...</td>\n",
       "      <td>John L. Dorman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93015</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>“The Illinois Republican Party and our country...</td>\n",
       "      <td>He’s a Nazi, Republicans Warn, but He’s Their ...</td>\n",
       "      <td>Liam Stack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93016</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Most prominent is the lighthouse. The 90-foot-...</td>\n",
       "      <td>Lighthouse Hill, Staten Island: Small and Semi...</td>\n",
       "      <td>Julie Lasky, Living In</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93017</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Photo\\r\\n\\r\\nHave you ridden on an airplane re...</td>\n",
       "      <td>Are Emotional-Support Animals a Scam?</td>\n",
       "      <td>Natalie Proulx, Student Opinion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93018 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  domain                                            content  \\\n",
       "0      beforeitsnews.com  Meditation Comprehension\\r\\n\\r\\nHeadline: Bitc...   \n",
       "1      beforeitsnews.com  AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2      beforeitsnews.com  ES Morning Update January 25th 2018\\r\\n\\r\\nHea...   \n",
       "3      beforeitsnews.com  Bang! Secret FISA Memo Released…You Won’t Beli...   \n",
       "4      beforeitsnews.com  Obama’s The Greatest Criminal In History Say T...   \n",
       "...                  ...                                                ...   \n",
       "93013        nytimes.com  Watching is The New York Times’s TV and film r...   \n",
       "93014        nytimes.com  WHERE TO GO NOW In Philadelphia, the Ultimate ...   \n",
       "93015        nytimes.com  “The Illinois Republican Party and our country...   \n",
       "93016        nytimes.com  Most prominent is the lighthouse. The 90-foot-...   \n",
       "93017        nytimes.com  Photo\\r\\n\\r\\nHave you ridden on an airplane re...   \n",
       "\n",
       "                                                   title  \\\n",
       "0                               Meditation Comprehension   \n",
       "1      AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2                    ES Morning Update January 25th 2018   \n",
       "3      Bang! Secret FISA Memo Released…You Won’t Beli...   \n",
       "4      Obama DOJ Bombshell: Investigators Just Uncove...   \n",
       "...                                                  ...   \n",
       "93013  A Starter Guide to Streaming Great South Korea...   \n",
       "93014  In Philadelphia, the Ultimate Eagles Celebrati...   \n",
       "93015  He’s a Nazi, Republicans Warn, but He’s Their ...   \n",
       "93016  Lighthouse Hill, Staten Island: Small and Semi...   \n",
       "93017              Are Emotional-Support Animals a Scam?   \n",
       "\n",
       "                               authors  type  \n",
       "0                   Ethan Indigo Smith     0  \n",
       "1                         Zurich Times     0  \n",
       "2                       Red Dragon Leo     0  \n",
       "3                           Lisa Haven     0  \n",
       "4                        Economic News     0  \n",
       "...                                ...   ...  \n",
       "93013                       Dakota Kim     1  \n",
       "93014                   John L. Dorman     1  \n",
       "93015                       Liam Stack     1  \n",
       "93016           Julie Lasky, Living In     1  \n",
       "93017  Natalie Proulx, Student Opinion     1  \n",
       "\n",
       "[93018 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['type'].replace({'fake':0,'reliable':1,'clickbait':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Meditation Comprehension\\r\\n\\r\\nHeadline: Bitc...</td>\n",
       "      <td>Meditation Comprehension</td>\n",
       "      <td>Ethan Indigo Smith</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>Zurich Times</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>ES Morning Update January 25th 2018\\r\\n\\r\\nHea...</td>\n",
       "      <td>ES Morning Update January 25th 2018</td>\n",
       "      <td>Red Dragon Leo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Bang! Secret FISA Memo Released…You Won’t Beli...</td>\n",
       "      <td>Bang! Secret FISA Memo Released…You Won’t Beli...</td>\n",
       "      <td>Lisa Haven</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Obama’s The Greatest Criminal In History Say T...</td>\n",
       "      <td>Obama DOJ Bombshell: Investigators Just Uncove...</td>\n",
       "      <td>Economic News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93013</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Watching is The New York Times’s TV and film r...</td>\n",
       "      <td>A Starter Guide to Streaming Great South Korea...</td>\n",
       "      <td>Dakota Kim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93014</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>WHERE TO GO NOW In Philadelphia, the Ultimate ...</td>\n",
       "      <td>In Philadelphia, the Ultimate Eagles Celebrati...</td>\n",
       "      <td>John L. Dorman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93015</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>“The Illinois Republican Party and our country...</td>\n",
       "      <td>He’s a Nazi, Republicans Warn, but He’s Their ...</td>\n",
       "      <td>Liam Stack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93016</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Most prominent is the lighthouse. The 90-foot-...</td>\n",
       "      <td>Lighthouse Hill, Staten Island: Small and Semi...</td>\n",
       "      <td>Julie Lasky, Living In</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93017</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Photo\\r\\n\\r\\nHave you ridden on an airplane re...</td>\n",
       "      <td>Are Emotional-Support Animals a Scam?</td>\n",
       "      <td>Natalie Proulx, Student Opinion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93018 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  domain                                            content  \\\n",
       "0      beforeitsnews.com  Meditation Comprehension\\r\\n\\r\\nHeadline: Bitc...   \n",
       "1      beforeitsnews.com  AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2      beforeitsnews.com  ES Morning Update January 25th 2018\\r\\n\\r\\nHea...   \n",
       "3      beforeitsnews.com  Bang! Secret FISA Memo Released…You Won’t Beli...   \n",
       "4      beforeitsnews.com  Obama’s The Greatest Criminal In History Say T...   \n",
       "...                  ...                                                ...   \n",
       "93013        nytimes.com  Watching is The New York Times’s TV and film r...   \n",
       "93014        nytimes.com  WHERE TO GO NOW In Philadelphia, the Ultimate ...   \n",
       "93015        nytimes.com  “The Illinois Republican Party and our country...   \n",
       "93016        nytimes.com  Most prominent is the lighthouse. The 90-foot-...   \n",
       "93017        nytimes.com  Photo\\r\\n\\r\\nHave you ridden on an airplane re...   \n",
       "\n",
       "                                                   title  \\\n",
       "0                               Meditation Comprehension   \n",
       "1      AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2                    ES Morning Update January 25th 2018   \n",
       "3      Bang! Secret FISA Memo Released…You Won’t Beli...   \n",
       "4      Obama DOJ Bombshell: Investigators Just Uncove...   \n",
       "...                                                  ...   \n",
       "93013  A Starter Guide to Streaming Great South Korea...   \n",
       "93014  In Philadelphia, the Ultimate Eagles Celebrati...   \n",
       "93015  He’s a Nazi, Republicans Warn, but He’s Their ...   \n",
       "93016  Lighthouse Hill, Staten Island: Small and Semi...   \n",
       "93017              Are Emotional-Support Animals a Scam?   \n",
       "\n",
       "                               authors  type  \n",
       "0                   Ethan Indigo Smith     0  \n",
       "1                         Zurich Times     0  \n",
       "2                       Red Dragon Leo     0  \n",
       "3                           Lisa Haven     0  \n",
       "4                        Economic News     0  \n",
       "...                                ...   ...  \n",
       "93013                       Dakota Kim     1  \n",
       "93014                   John L. Dorman     1  \n",
       "93015                       Liam Stack     1  \n",
       "93016           Julie Lasky, Living In     1  \n",
       "93017  Natalie Proulx, Student Opinion     1  \n",
       "\n",
       "[93018 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    59785\n",
       "0    33233\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x=data.iloc[:,0:-1]\n",
    "data_y=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Meditation Comprehension\\r\\n\\r\\nHeadline: Bitc...</td>\n",
       "      <td>Meditation Comprehension</td>\n",
       "      <td>Ethan Indigo Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>Zurich Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>ES Morning Update January 25th 2018\\r\\n\\r\\nHea...</td>\n",
       "      <td>ES Morning Update January 25th 2018</td>\n",
       "      <td>Red Dragon Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Bang! Secret FISA Memo Released…You Won’t Beli...</td>\n",
       "      <td>Bang! Secret FISA Memo Released…You Won’t Beli...</td>\n",
       "      <td>Lisa Haven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Obama’s The Greatest Criminal In History Say T...</td>\n",
       "      <td>Obama DOJ Bombshell: Investigators Just Uncove...</td>\n",
       "      <td>Economic News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93013</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Watching is The New York Times’s TV and film r...</td>\n",
       "      <td>A Starter Guide to Streaming Great South Korea...</td>\n",
       "      <td>Dakota Kim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93014</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>WHERE TO GO NOW In Philadelphia, the Ultimate ...</td>\n",
       "      <td>In Philadelphia, the Ultimate Eagles Celebrati...</td>\n",
       "      <td>John L. Dorman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93015</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>“The Illinois Republican Party and our country...</td>\n",
       "      <td>He’s a Nazi, Republicans Warn, but He’s Their ...</td>\n",
       "      <td>Liam Stack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93016</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Most prominent is the lighthouse. The 90-foot-...</td>\n",
       "      <td>Lighthouse Hill, Staten Island: Small and Semi...</td>\n",
       "      <td>Julie Lasky, Living In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93017</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>Photo\\r\\n\\r\\nHave you ridden on an airplane re...</td>\n",
       "      <td>Are Emotional-Support Animals a Scam?</td>\n",
       "      <td>Natalie Proulx, Student Opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93018 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  domain                                            content  \\\n",
       "0      beforeitsnews.com  Meditation Comprehension\\r\\n\\r\\nHeadline: Bitc...   \n",
       "1      beforeitsnews.com  AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2      beforeitsnews.com  ES Morning Update January 25th 2018\\r\\n\\r\\nHea...   \n",
       "3      beforeitsnews.com  Bang! Secret FISA Memo Released…You Won’t Beli...   \n",
       "4      beforeitsnews.com  Obama’s The Greatest Criminal In History Say T...   \n",
       "...                  ...                                                ...   \n",
       "93013        nytimes.com  Watching is The New York Times’s TV and film r...   \n",
       "93014        nytimes.com  WHERE TO GO NOW In Philadelphia, the Ultimate ...   \n",
       "93015        nytimes.com  “The Illinois Republican Party and our country...   \n",
       "93016        nytimes.com  Most prominent is the lighthouse. The 90-foot-...   \n",
       "93017        nytimes.com  Photo\\r\\n\\r\\nHave you ridden on an airplane re...   \n",
       "\n",
       "                                                   title  \\\n",
       "0                               Meditation Comprehension   \n",
       "1      AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2                    ES Morning Update January 25th 2018   \n",
       "3      Bang! Secret FISA Memo Released…You Won’t Beli...   \n",
       "4      Obama DOJ Bombshell: Investigators Just Uncove...   \n",
       "...                                                  ...   \n",
       "93013  A Starter Guide to Streaming Great South Korea...   \n",
       "93014  In Philadelphia, the Ultimate Eagles Celebrati...   \n",
       "93015  He’s a Nazi, Republicans Warn, but He’s Their ...   \n",
       "93016  Lighthouse Hill, Staten Island: Small and Semi...   \n",
       "93017              Are Emotional-Support Animals a Scam?   \n",
       "\n",
       "                               authors  \n",
       "0                   Ethan Indigo Smith  \n",
       "1                         Zurich Times  \n",
       "2                       Red Dragon Leo  \n",
       "3                           Lisa Haven  \n",
       "4                        Economic News  \n",
       "...                                ...  \n",
       "93013                       Dakota Kim  \n",
       "93014                   John L. Dorman  \n",
       "93015                       Liam Stack  \n",
       "93016           Julie Lasky, Living In  \n",
       "93017  Natalie Proulx, Student Opinion  \n",
       "\n",
       "[93018 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74414, 4)\n",
      "(18604, 4)\n",
      "Final size of train/test :  (74414, 4) / (18604, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train_x, data_test_x, data_train_y, data_test_y = train_test_split(data_x,data_y,test_size=0.2,random_state=12)\n",
    "print(data_train_x.shape)\n",
    "print(data_test_x.shape)\n",
    "\n",
    "# mega_test_x : Final testing file with statements\n",
    "# mega_test_y : Final testing file with ratings\n",
    "\n",
    "print(\"Final size of train/test : \",data_train_x.shape,\"/\",data_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the vocab(dictionary) size\n",
    "\n",
    "def dic_size(data_train):\n",
    "    tokenizer = Tokenizer()#this is the dictionary that is built , no memory error here\n",
    "    tokenizer.fit_on_texts(data_train)\n",
    "    vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "    print(vocab_size)\n",
    "    return vocab_size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['domain', 'content', 'title', 'authors', 'type'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "460519\n",
      "56462\n",
      "14161\n",
      "vocab_size 460519\n"
     ]
    }
   ],
   "source": [
    "v1=dic_size(data_train_x.domain)\n",
    "v2=dic_size(data_train_x.content)\n",
    "v3=dic_size(data_train_x.title)\n",
    "v4=dic_size(data_train_x.authors)\n",
    "vocab_size=max(v1,v2,v3,v4)\n",
    "print('vocab_size',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_len(data):\n",
    "    maxlen=0\n",
    "    for i in data:\n",
    "        if(len(i)>maxlen):\n",
    "            maxlen=len(i)\n",
    "    print(maxlen)\n",
    "    return maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "def tokenize(train_data,test_data):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    em_data_train = tokenizer.texts_to_sequences(train_data)\n",
    "    em_data_test= tokenizer.texts_to_sequences(test_data)\n",
    "    \n",
    "    return em_data_train,em_data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def padding(token_train_data,token_test_data,maxlen):\n",
    "    em_data_train_pad= pad_sequences(token_train_data, padding='post', maxlen=maxlen)\n",
    "    em_data_test_pad= pad_sequences(token_test_data, padding='post', maxlen=maxlen)\n",
    "    return em_data_train_pad,em_data_test_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_data_train_domain,em_data_test_domain=tokenize(data_train_x.domain,data_test_x.domain)\n",
    "em_data_train_content,em_data_test_content=tokenize(data_train_x.content,data_test_x.content)\n",
    "em_data_train_title,em_data_test_title=tokenize(data_train_x.title,data_test_x.title)\n",
    "em_data_train_authors,em_data_test_authors=tokenize(data_train_x.authors,data_test_x.authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "33402\n",
      "40\n",
      "114\n",
      "maxlen 33402\n"
     ]
    }
   ],
   "source": [
    "m1=max_len(em_data_train_domain)\n",
    "m2=max_len(em_data_train_content)\n",
    "m3=max_len(em_data_train_title)\n",
    "m4=max_len(em_data_train_authors)\n",
    "maxlen=max(m1,m2,m3,m4)\n",
    "print('maxlen',maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_data_train_paddomain,em_data_test_paddomain=padding(em_data_train_domain,em_data_test_domain,4)\n",
    "em_data_train_padcontent,em_data_test_padcontent=padding(em_data_train_content,em_data_test_content,33402)\n",
    "em_data_train_padtitle,em_data_test_padtitle=padding(em_data_train_title,em_data_test_title,40)\n",
    "em_data_train_padauthors,em_data_test_padauthors=padding(em_data_train_authors,em_data_test_authors,114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 44\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "domain_in (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "content_in (InputLayer)         (None, 33402)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authors_in (InputLayer)         (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 4, 25)        11512975    domain_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 33402, 25)    11512975    content_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 40, 25)       11512975    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 114, 25)      11512975    authors_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 25)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 25)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 25)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 25)           0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100)          0           global_max_pooling1d_5[0][0]     \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 66)           6666        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 44)           2948        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op (Dense)                      (None, 1)            45          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,061,559\n",
      "Trainable params: 46,061,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalMaxPool1D\n",
    "\n",
    "embedding_dim = 25\n",
    "h1=int(2/3*100)\n",
    "h2=int(2/3*h1)\n",
    "print(h1,h2)\n",
    "\n",
    "domain_in = Input(shape=(4,), name='domain_in')\n",
    "content_in = Input(shape=(33402,), name='content_in')\n",
    "title_in = Input(shape=(40,), name='title_in')\n",
    "authors_in = Input(shape=(114,), name='authors_in')\n",
    "\n",
    "domain_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=4)(domain_in)\n",
    "content_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=33402)(content_in)\n",
    "title_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=40)(title_in)\n",
    "authors_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=114)(authors_in)\n",
    "\n",
    "domain_pool = GlobalMaxPool1D()(domain_embed)\n",
    "content_pool = GlobalMaxPool1D()(content_embed)\n",
    "title_pool = GlobalMaxPool1D()(title_embed)\n",
    "authors_pool = GlobalMaxPool1D()(authors_embed)\n",
    "\n",
    "all_d = concatenate([domain_pool, content_pool,title_pool,authors_pool])\n",
    "\n",
    "d1 = Dense(h1, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(all_d)\n",
    "d2 = Dense(h2, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(d1)\n",
    "\n",
    "op = Dense(1, activation='sigmoid', name='op')(d2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[domain_in,content_in,title_in,authors_in], outputs=[op])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel(train_domain,train_content,train_title,train_authors,train_y):\n",
    "    print('loading model')\n",
    "    #model=load_model('model.h5')\n",
    "    print('model loaded')\n",
    "    print('Running tokpad')\n",
    "   \n",
    "    print('Tokpad is done')\n",
    "    print('Start training')\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    h=model.fit({'domain_in': train_domain, 'content_in': train_content, 'title_in':train_title,'authors_in':train_authors},{'op': train_y},epochs=10, batch_size=10)\n",
    "    print('Fitting is done')\n",
    "    print('saving the model')\n",
    "    model.save(\"model.h5\")\n",
    "    print('model is saved')\n",
    "    print(\"Cleaning Ram\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "model loaded\n",
      "Running tokpad\n",
      "Tokpad is done\n",
      "Start training\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 824s 82ms/step - loss: 0.2036 - accuracy: 0.9735\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 827s 83ms/step - loss: 0.0389 - accuracy: 0.9995\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 825s 82ms/step - loss: 0.0251 - accuracy: 0.9994\n",
      "Epoch 4/10\n",
      " 6170/10000 [=================>............] - ETA: 5:15 - loss: 0.0188 - accuracy: 1.0000Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-08 12:38:55,510 - INFO     - Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6180/10000 [=================>............] - ETA: 5:14 - loss: 0.0187 - accuracy: 1.0000Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-08 12:38:56,920 - INFO     - Executing shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 823s 82ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 820s 82ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 825s 83ms/step - loss: 0.0119 - accuracy: 0.9999\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 820s 82ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 825s 82ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 818s 82ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 816s 82ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Fitting is done\n",
      "saving the model\n",
      "model is saved\n",
      "Cleaning Ram\n"
     ]
    }
   ],
   "source": [
    "trainmodel(em_data_train_paddomain[0:10000],em_data_train_padcontent[:10000],em_data_train_padtitle[:10000],em_data_train_padauthors[:10000],data_train_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    \\\n",
    "     \n",
    "    \\ \n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel1(train_domain,train_content,train_title,train_authors,train_y):\n",
    "    model=load_model('model.h5')\n",
    "    print('model loaded')\n",
    "    print('Running tokpad')\n",
    "   \n",
    "    print('Tokpad is done')\n",
    "    print('Start training')\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    h=model.fit({'domain_in': train_domain, 'content_in': train_content, 'title_in':train_title,'authors_in':train_authors},{'op': train_y},epochs=10, batch_size=10)\n",
    "    print('Fitting is done')\n",
    "    print('saving the model')\n",
    "    model.save(\"model.h5\")\n",
    "    print('model is saved')\n",
    "    print(\"Cleaning Ram\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 44\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "domain_in (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "content_in (InputLayer)         (None, 33402)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authors_in (InputLayer)         (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 4, 25)        11512975    domain_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 33402, 25)    11512975    content_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 40, 25)       11512975    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 114, 25)      11512975    authors_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 25)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 25)           0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 25)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 25)           0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 100)          0           global_max_pooling1d_9[0][0]     \n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 66)           6666        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 44)           2948        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op (Dense)                      (None, 1)            45          dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,061,559\n",
      "Trainable params: 46,061,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 25\n",
    "h1=int(2/3*100)\n",
    "h2=int(2/3*h1)\n",
    "print(h1,h2)\n",
    "\n",
    "domain_in = Input(shape=(4,), name='domain_in')\n",
    "content_in = Input(shape=(33402,), name='content_in')\n",
    "title_in = Input(shape=(40,), name='title_in')\n",
    "authors_in = Input(shape=(114,), name='authors_in')\n",
    "\n",
    "domain_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=4)(domain_in)\n",
    "content_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=33402)(content_in)\n",
    "title_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=40)(title_in)\n",
    "authors_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=114)(authors_in)\n",
    "\n",
    "domain_pool = GlobalMaxPool1D()(domain_embed)\n",
    "content_pool = GlobalMaxPool1D()(content_embed)\n",
    "title_pool = GlobalMaxPool1D()(title_embed)\n",
    "authors_pool = GlobalMaxPool1D()(authors_embed)\n",
    "\n",
    "all_d = concatenate([domain_pool, content_pool,title_pool,authors_pool])\n",
    "\n",
    "d1 = Dense(h1, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(all_d)\n",
    "d2 = Dense(h2, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(d1)\n",
    "\n",
    "op = Dense(1, activation='sigmoid', name='op')(d2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[domain_in,content_in,title_in,authors_in], outputs=[op])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\3 idiots\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Running tokpad\n",
      "Tokpad is done\n",
      "Start training\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 809s 81ms/step - loss: 0.0067 - accuracy: 0.9996\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 811s 81ms/step - loss: 0.0053 - accuracy: 0.9998\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 810s 81ms/step - loss: 0.0045 - accuracy: 0.9999\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 807s 81ms/step - loss: 0.0043 - accuracy: 0.9998\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 807s 81ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 813s 81ms/step - loss: 0.0038 - accuracy: 0.9999\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 807s 81ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 0.0030 - accuracy: 0.9999\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 0.0026 - accuracy: 0.9999\n",
      "Fitting is done\n",
      "saving the model\n",
      "model is saved\n",
      "Cleaning Ram\n"
     ]
    }
   ],
   "source": [
    "trainmodel1(em_data_train_paddomain[10000:20000],em_data_train_padcontent[10000:20000],em_data_train_padtitle[10000:20000],em_data_train_padauthors[10000:20000],data_train_y[10000:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 44\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "domain_in (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "content_in (InputLayer)         (None, 33402)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authors_in (InputLayer)         (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 4, 25)        11512975    domain_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 33402, 25)    11512975    content_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 40, 25)       11512975    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 114, 25)      11512975    authors_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 25)           0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 25)           0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 25)           0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 25)           0           embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 100)          0           global_max_pooling1d_13[0][0]    \n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 66)           6666        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 44)           2948        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op (Dense)                      (None, 1)            45          dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,061,559\n",
      "Trainable params: 46,061,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 25\n",
    "h1=int(2/3*100)\n",
    "h2=int(2/3*h1)\n",
    "print(h1,h2)\n",
    "\n",
    "domain_in = Input(shape=(4,), name='domain_in')\n",
    "content_in = Input(shape=(33402,), name='content_in')\n",
    "title_in = Input(shape=(40,), name='title_in')\n",
    "authors_in = Input(shape=(114,), name='authors_in')\n",
    "\n",
    "domain_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=4)(domain_in)\n",
    "content_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=33402)(content_in)\n",
    "title_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=40)(title_in)\n",
    "authors_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=114)(authors_in)\n",
    "\n",
    "domain_pool = GlobalMaxPool1D()(domain_embed)\n",
    "content_pool = GlobalMaxPool1D()(content_embed)\n",
    "title_pool = GlobalMaxPool1D()(title_embed)\n",
    "authors_pool = GlobalMaxPool1D()(authors_embed)\n",
    "\n",
    "all_d = concatenate([domain_pool, content_pool,title_pool,authors_pool])\n",
    "\n",
    "d1 = Dense(h1, activation='relu')(all_d)\n",
    "d2 = Dense(h2, activation='relu')(d1)\n",
    "\n",
    "op = Dense(1, activation='sigmoid', name='op')(d2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[domain_in,content_in,title_in,authors_in], outputs=[op])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Running tokpad\n",
      "Tokpad is done\n",
      "Start training\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 820s 82ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 833s 83ms/step - loss: 0.0027 - accuracy: 0.9998\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 820s 82ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 807s 81ms/step - loss: 0.0024 - accuracy: 0.9999\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 808s 81ms/step - loss: 0.0035 - accuracy: 0.9998\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 805s 81ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 807s 81ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 805s 80ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Fitting is done\n",
      "saving the model\n",
      "model is saved\n",
      "Cleaning Ram\n"
     ]
    }
   ],
   "source": [
    "trainmodel1(em_data_train_paddomain[20000:30000],em_data_train_padcontent[20000:30000],em_data_train_padtitle[20000:30000],em_data_train_padauthors[20000:30000],data_train_y[20000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 44\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "domain_in (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "content_in (InputLayer)         (None, 33402)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authors_in (InputLayer)         (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 4, 25)        11512975    domain_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 33402, 25)    11512975    content_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 40, 25)       11512975    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 114, 25)      11512975    authors_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 25)           0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 25)           0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 25)           0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 25)           0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 100)          0           global_max_pooling1d_17[0][0]    \n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 66)           6666        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 44)           2948        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op (Dense)                      (None, 1)            45          dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 46,061,559\n",
      "Trainable params: 46,061,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 25\n",
    "h1=int(2/3*100)\n",
    "h2=int(2/3*h1)\n",
    "print(h1,h2)\n",
    "\n",
    "domain_in = Input(shape=(4,), name='domain_in')\n",
    "content_in = Input(shape=(33402,), name='content_in')\n",
    "title_in = Input(shape=(40,), name='title_in')\n",
    "authors_in = Input(shape=(114,), name='authors_in')\n",
    "\n",
    "domain_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=4)(domain_in)\n",
    "content_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=33402)(content_in)\n",
    "title_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=40)(title_in)\n",
    "authors_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=114)(authors_in)\n",
    "\n",
    "domain_pool = GlobalMaxPool1D()(domain_embed)\n",
    "content_pool = GlobalMaxPool1D()(content_embed)\n",
    "title_pool = GlobalMaxPool1D()(title_embed)\n",
    "authors_pool = GlobalMaxPool1D()(authors_embed)\n",
    "\n",
    "all_d = concatenate([domain_pool, content_pool,title_pool,authors_pool])\n",
    "\n",
    "d1 = Dense(h1, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(all_d)\n",
    "d2 = Dense(h2, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(d1)\n",
    "\n",
    "op = Dense(1, activation='sigmoid', name='op')(d2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[domain_in,content_in,title_in,authors_in], outputs=[op])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Running tokpad\n",
      "Tokpad is done\n",
      "Start training\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 810s 81ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 808s 81ms/step - loss: 0.0020 - accuracy: 0.9999\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 808s 81ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 809s 81ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 831s 83ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 841s 84ms/step - loss: 0.0027 - accuracy: 0.9999\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 816s 82ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 812s 81ms/step - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 814s 81ms/step - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 809s 81ms/step - loss: 0.0032 - accuracy: 0.9998\n",
      "Fitting is done\n",
      "saving the model\n",
      "model is saved\n",
      "Cleaning Ram\n"
     ]
    }
   ],
   "source": [
    "trainmodel1(em_data_train_paddomain[30000:40000],em_data_train_padcontent[30000:40000],em_data_train_padtitle[30000:40000],em_data_train_padauthors[30000:40000],data_train_y[30000:40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 44\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "domain_in (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "content_in (InputLayer)         (None, 33402)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authors_in (InputLayer)         (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 4, 25)        11512975    domain_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 33402, 25)    11512975    content_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 40, 25)       11512975    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 114, 25)      11512975    authors_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 25)           0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 25)           0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 25)           0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 25)           0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 100)          0           global_max_pooling1d_21[0][0]    \n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 66)           6666        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 44)           2948        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "op (Dense)                      (None, 1)            45          dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 46,061,559\n",
      "Trainable params: 46,061,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 25\n",
    "h1=int(2/3*100)\n",
    "h2=int(2/3*h1)\n",
    "print(h1,h2)\n",
    "\n",
    "domain_in = Input(shape=(4,), name='domain_in')\n",
    "content_in = Input(shape=(33402,), name='content_in')\n",
    "title_in = Input(shape=(40,), name='title_in')\n",
    "authors_in = Input(shape=(114,), name='authors_in')\n",
    "\n",
    "domain_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=4)(domain_in)\n",
    "content_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=33402)(content_in)\n",
    "title_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=40)(title_in)\n",
    "authors_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=114)(authors_in)\n",
    "\n",
    "domain_pool = GlobalMaxPool1D()(domain_embed)\n",
    "content_pool = GlobalMaxPool1D()(content_embed)\n",
    "title_pool = GlobalMaxPool1D()(title_embed)\n",
    "authors_pool = GlobalMaxPool1D()(authors_embed)\n",
    "\n",
    "all_d = concatenate([domain_pool, content_pool,title_pool,authors_pool])\n",
    "\n",
    "d1 = Dense(h1, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(all_d)\n",
    "d2 = Dense(h2, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(d1)\n",
    "\n",
    "op = Dense(1, activation='sigmoid', name='op')(d2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[domain_in,content_in,title_in,authors_in], outputs=[op])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Running tokpad\n",
      "Tokpad is done\n",
      "Start training\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 815s 82ms/step - loss: 0.0034 - accuracy: 0.9997\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 813s 81ms/step - loss: 0.0015 - accuracy: 0.9999\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 817s 82ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 832s 83ms/step - loss: 0.0016 - accuracy: 0.9999\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 805s 80ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 811s 81ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 810s 81ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 809s 81ms/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 809s 81ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 808s 81ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Fitting is done\n",
      "saving the model\n",
      "model is saved\n",
      "Cleaning Ram\n"
     ]
    }
   ],
   "source": [
    "trainmodel1(em_data_train_paddomain[40000:50000],em_data_train_padcontent[40000:50000],em_data_train_padtitle[40000:50000],em_data_train_padauthors[40000:50000],data_train_y[40000:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 44\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "domain_in (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "content_in (InputLayer)         (None, 33402)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authors_in (InputLayer)         (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 4, 25)        11512975    domain_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 33402, 25)    11512975    content_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 40, 25)       11512975    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 114, 25)      11512975    authors_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 25)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 25)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 25)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 25)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 66)           6666        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 44)           2948        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op (Dense)                      (None, 1)            45          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,061,559\n",
      "Trainable params: 46,061,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 25\n",
    "h1=int(2/3*100)\n",
    "h2=int(2/3*h1)\n",
    "print(h1,h2)\n",
    "\n",
    "domain_in = Input(shape=(4,), name='domain_in')\n",
    "content_in = Input(shape=(33402,), name='content_in')\n",
    "title_in = Input(shape=(40,), name='title_in')\n",
    "authors_in = Input(shape=(114,), name='authors_in')\n",
    "\n",
    "domain_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=4)(domain_in)\n",
    "content_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=33402)(content_in)\n",
    "title_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=40)(title_in)\n",
    "authors_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=114)(authors_in)\n",
    "\n",
    "domain_pool = GlobalMaxPool1D()(domain_embed)\n",
    "content_pool = GlobalMaxPool1D()(content_embed)\n",
    "title_pool = GlobalMaxPool1D()(title_embed)\n",
    "authors_pool = GlobalMaxPool1D()(authors_embed)\n",
    "\n",
    "all_d = concatenate([domain_pool, content_pool,title_pool,authors_pool])\n",
    "\n",
    "d1 = Dense(h1, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(all_d)\n",
    "d2 = Dense(h2, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(d1)\n",
    "\n",
    "op = Dense(1, activation='sigmoid', name='op')(d2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[domain_in,content_in,title_in,authors_in], outputs=[op])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\3 idiots\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Running tokpad\n",
      "Tokpad is done\n",
      "Start training\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 820s 82ms/step - loss: 0.0027 - accuracy: 0.9999\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 813s 81ms/step - loss: 9.5435e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 814s 81ms/step - loss: 0.0016 - accuracy: 0.9999\n",
      "Epoch 4/10\n",
      " 8910/10000 [=========================>....] - ETA: 1:28 - loss: 8.4334e-04 - accuracy: 1.0000Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-09 00:57:26,107 - INFO     - Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8920/10000 [=========================>....] - ETA: 1:27 - loss: 8.4314e-04 - accuracy: 1.0000Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-09 00:57:27,275 - INFO     - Executing shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 813s 81ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 811s 81ms/step - loss: 8.9324e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 812s 81ms/step - loss: 0.0046 - accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 826s 83ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 805s 80ms/step - loss: 8.8939e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 7.4987e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Fitting is done\n",
      "saving the model\n",
      "model is saved\n",
      "Cleaning Ram\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-67bcaebf212a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainmodel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mem_data_train_paddomain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mem_data_train_padcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mem_data_train_padtitle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mem_data_train_padauthors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_train_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-21b63dd5744c>\u001b[0m in \u001b[0;36mtrainmodel1\u001b[1;34m(train_domain, train_content, train_title, train_authors, train_y)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model is saved'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cleaning Ram\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "trainmodel1(em_data_train_paddomain[50000:60000],em_data_train_padcontent[50000:60000],em_data_train_padtitle[50000:60000],em_data_train_padauthors[50000:60000],data_train_y[50000:60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8143"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 44\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "domain_in (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "content_in (InputLayer)         (None, 33402)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authors_in (InputLayer)         (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 4, 25)        11512975    domain_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 33402, 25)    11512975    content_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 40, 25)       11512975    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 114, 25)      11512975    authors_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 25)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 25)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 25)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 25)           0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100)          0           global_max_pooling1d_5[0][0]     \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 66)           6666        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 44)           2948        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op (Dense)                      (None, 1)            45          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,061,559\n",
      "Trainable params: 46,061,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 25\n",
    "h1=int(2/3*100)\n",
    "h2=int(2/3*h1)\n",
    "print(h1,h2)\n",
    "\n",
    "domain_in = Input(shape=(4,), name='domain_in')\n",
    "content_in = Input(shape=(33402,), name='content_in')\n",
    "title_in = Input(shape=(40,), name='title_in')\n",
    "authors_in = Input(shape=(114,), name='authors_in')\n",
    "\n",
    "domain_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=4)(domain_in)\n",
    "content_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=33402)(content_in)\n",
    "title_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=40)(title_in)\n",
    "authors_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=114)(authors_in)\n",
    "\n",
    "domain_pool = GlobalMaxPool1D()(domain_embed)\n",
    "content_pool = GlobalMaxPool1D()(content_embed)\n",
    "title_pool = GlobalMaxPool1D()(title_embed)\n",
    "authors_pool = GlobalMaxPool1D()(authors_embed)\n",
    "\n",
    "all_d = concatenate([domain_pool, content_pool,title_pool,authors_pool])\n",
    "\n",
    "d1 = Dense(h1, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(all_d)\n",
    "d2 = Dense(h2, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(d1)\n",
    "\n",
    "op = Dense(1, activation='sigmoid', name='op')(d2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[domain_in,content_in,title_in,authors_in], outputs=[op])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\3 idiots\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Running tokpad\n",
      "Tokpad is done\n",
      "Start training\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 911s 91ms/step - loss: 0.0029 - accuracy: 0.9998\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 847s 85ms/step - loss: 8.1797e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 8.3162e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      " 4770/10000 [=============>................] - ETA: 7:04 - loss: 6.9530e-04 - accuracy: 1.0000Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-11 23:01:12,995 - INFO     - Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4830/10000 [=============>................] - ETA: 6:59 - loss: 6.9517e-04 - accuracy: 1.0000Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-11 23:01:18,260 - INFO     - Executing shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 811s 81ms/step - loss: 7.6717e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 830s 83ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 820s 82ms/step - loss: 7.3556e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 808s 81ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 808s 81ms/step - loss: 0.0039 - accuracy: 0.9999\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 808s 81ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 806s 81ms/step - loss: 0.0042 - accuracy: 0.9997\n",
      "Fitting is done\n",
      "saving the model\n",
      "model is saved\n",
      "Cleaning Ram\n"
     ]
    }
   ],
   "source": [
    "trainmodel1(em_data_train_paddomain[60000:70000],em_data_train_padcontent[60000:70000],em_data_train_padtitle[60000:70000],em_data_train_padauthors[60000:70000],data_train_y[60000:70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 44\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "domain_in (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "content_in (InputLayer)         (None, 33402)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authors_in (InputLayer)         (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 4, 25)        11512975    domain_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 33402, 25)    11512975    content_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 40, 25)       11512975    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 114, 25)      11512975    authors_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 25)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 25)           0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 25)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 25)           0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 100)          0           global_max_pooling1d_9[0][0]     \n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 66)           6666        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 44)           2948        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op (Dense)                      (None, 1)            45          dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,061,559\n",
      "Trainable params: 46,061,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 25\n",
    "h1=int(2/3*100)\n",
    "h2=int(2/3*h1)\n",
    "print(h1,h2)\n",
    "\n",
    "domain_in = Input(shape=(4,), name='domain_in')\n",
    "content_in = Input(shape=(33402,), name='content_in')\n",
    "title_in = Input(shape=(40,), name='title_in')\n",
    "authors_in = Input(shape=(114,), name='authors_in')\n",
    "\n",
    "domain_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=4)(domain_in)\n",
    "content_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=33402)(content_in)\n",
    "title_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=40)(title_in)\n",
    "authors_embed = Embedding(output_dim=embedding_dim, input_dim=460519, input_length=114)(authors_in)\n",
    "\n",
    "domain_pool = GlobalMaxPool1D()(domain_embed)\n",
    "content_pool = GlobalMaxPool1D()(content_embed)\n",
    "title_pool = GlobalMaxPool1D()(title_embed)\n",
    "authors_pool = GlobalMaxPool1D()(authors_embed)\n",
    "\n",
    "all_d = concatenate([domain_pool, content_pool,title_pool,authors_pool])\n",
    "\n",
    "d1 = Dense(h1, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(all_d)\n",
    "d2 = Dense(h2, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(d1)\n",
    "\n",
    "op = Dense(1, activation='sigmoid', name='op')(d2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[domain_in,content_in,title_in,authors_in], outputs=[op])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Running tokpad\n",
      "Tokpad is done\n",
      "Start training\n",
      "Epoch 1/10\n",
      "4414/4414 [==============================] - 359s 81ms/step - loss: 0.0062 - accuracy: 0.9995\n",
      "Epoch 2/10\n",
      "4414/4414 [==============================] - 357s 81ms/step - loss: 0.0041 - accuracy: 0.9998\n",
      "Epoch 3/10\n",
      "4414/4414 [==============================] - 358s 81ms/step - loss: 0.0022 - accuracy: 0.9998\n",
      "Epoch 4/10\n",
      "4414/4414 [==============================] - 360s 82ms/step - loss: 0.0050 - accuracy: 0.9998\n",
      "Epoch 5/10\n",
      "4414/4414 [==============================] - 358s 81ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 6/10\n",
      "4414/4414 [==============================] - 359s 81ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 7/10\n",
      "4414/4414 [==============================] - 372s 84ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "4414/4414 [==============================] - 400s 91ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4414/4414 [==============================] - 378s 86ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 10/10\n",
      "4414/4414 [==============================] - 420s 95ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "Fitting is done\n",
      "saving the model\n",
      "model is saved\n",
      "Cleaning Ram\n"
     ]
    }
   ],
   "source": [
    "trainmodel1(em_data_train_paddomain[70000:74414],em_data_train_padcontent[70000:74414],em_data_train_padtitle[70000:74414],em_data_train_padauthors[70000:74414],data_train_y[70000:74414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\3 idiots\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''em_data_train_paddomain,em_data_test_paddomain=padding(em_data_train_domain,em_data_test_domain,4)\n",
    "em_data_train_padcontent,em_data_test_padcontent=padding(em_data_train_content,em_data_test_content,33402)\n",
    "em_data_train_padtitle,em_data_test_padtitle=padding(em_data_train_title,em_data_test_title,40)\n",
    "em_data_train_padauthors,em_data_test_padauthors=padding(em_data_train_authors,em_data_test_authors,114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18604/18604 [==============================] - 85s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model1=load_model('pontersr2.h5')\n",
    "results = model1.evaluate(x={'domain_in': em_data_test_paddomain, 'content_in': em_data_test_padcontent, 'title_in':em_data_test_padtitle,'authors_in':em_data_test_padauthors},y={'op': data_test_y}, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.003366823025178737, 1.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
